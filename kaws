#!/usr/bin/env bash

# Input Variables:
# Environment variable | Command flag | Required |    Default   
# ---------------------------------------------------------------
# KAWS_KEY_NAME        | --key-pair   |   YES    | 
# KAWS_DOMAIN_NAME     | --domain     |   YES    | 
# CONFIG_FILE          | --conf       |    NO    | ./kaws.conf
# CONFIG_DIR           | --conf-dir   |    NO    | ./kube-aws-kaws-kube
# KAWS_CLUSTER_NAME    | --cluster    |    NO    | kaws-kube
# KAWS_BUCKET          | --s3         |    NO    | kaws-kube
# AWS_PROFILE          | --profile    |    NO    | default
# AWS_REGION           |              |    NO    | us-west-2
# KAWS_KMS             |              |    NO    |
# KAWS_PUBLIC_SUBNET_A_CIDR           |    NO    | 10.0.101.0/24
# KAWS_PUBLIC_SUBNET_B_CIDR           |    NO    | 10.0.102.0/24
# KAWS_PUBLIC_SUBNET_C_CIDR           |    NO    | 10.0.103.0/24
# ---------------------------------------------------------------

SCRIPT_DIR="$( cd "$( dirname "$0" )" && pwd )"
SCRIPT_NAME="$( basename "$0" )"

# Input variables can be defined in the kaws.conf file
DEFAULT_CONFIG_FILE=./${SCRIPT_NAME}.conf

DEFAULT_CLUSTER_NAME=kaws-kube
DEFAULT_ENVIRONMENT=Development
DEFAULT_AWS_PROFILE=default
DEFAULT_REGION=us-west-2

DEFAULT_PUBLIC_SUBNET_A_CIDR=10.0.101.0/24
DEFAULT_PUBLIC_SUBNET_B_CIDR=10.0.102.0/24
DEFAULT_PUBLIC_SUBNET_C_CIDR=10.0.103.0/24

DEFAULT_CUSTER_SIZE="1:N:1"

# Cluster Size:
# M:W:E = Number of Masters (M) : Workers (W) : etcd (E) nodes
# 1:1:1 = One master, one etcd in one Availability Zone. One worker per Availability Zone.
# 1:N:1 = One master, one etcd in one Availability Zone. 1 - 3 workers per Availability Zone.
# N:N:1 = One etcd in one Availability Zone. 1 - 2 masters per Availability Zone. 1 - 3 workers per Availability Zone.
# N:N:N = NOT WORKING. 1 etcd per AZ is not working yet.
# N:1:? = Does not exists.

# DEFAULT_PRIVATE_SUBNET_A_CIDR=10.0.1.0/24
# DEFAULT_PRIVATE_SUBNET_B_CIDR=10.0.2.0/24
# DEFAULT_PRIVATE_SUBNET_C_CIDR=10.0.3.0/24

# Get defaults if not assigned
: ${CONFIG_FILE:=$DEFAULT_CONFIG_FILE}
: ${KAWS_CLUSTER_NAME:=$DEFAULT_CLUSTER_NAME}
: ${KAWS_ENVIRONMENT:=$DEFAULT_ENVIRONMENT}
: ${AWS_PROFILE:=$DEFAULT_AWS_PROFILE}
: ${AWS_REGION:=$DEFAULT_REGION}

: ${KAWS_PUBLIC_SUBNET_A_CIDR:=$DEFAULT_PUBLIC_SUBNET_A_CIDR}
: ${KAWS_PUBLIC_SUBNET_B_CIDR:=$DEFAULT_PUBLIC_SUBNET_B_CIDR}
: ${KAWS_PUBLIC_SUBNET_C_CIDR:=$DEFAULT_PUBLIC_SUBNET_C_CIDR}

: ${KAWS_CUSTER_SIZE:=$DEFAULT_CUSTER_SIZE}

DEFAULT_CONFIG_DIR_NAME="kube-aws-${KAWS_CLUSTER_NAME}"
DEFAULT_CONFIG_DIR="${PWD}/${DEFAULT_CONFIG_DIR_NAME}"
: ${CONFIG_DIR:=$DEFAULT_CONFIG_DIR}

# Get settings from configuration file
[[ -f ${CONFIG_FILE} ]] && source ${CONFIG_FILE}

# Global Variables
# ------------------------------------------------------------------------------
C_STD="\033[0m"
C_RED="\033[31m"
C_GREEN="\033[32m"
C_YELLOW="\033[33m"
C_BLUE="\033[34m"
C_PURPLE="\033[35m"
C_WHITEBOLD="\033[97;1m"
I_CROSS="\xe2\x95\xb3"
I_CHECK="\xe2\x9c\x94"
I_BULLET="\xe2\x80\xa2"

# Enable debug with '--debug' parameter or with env variables / config file
: ${KAWS_DEBUG:=0}
# Enable deeper debug with '--debug2' parameter
DEEP_DEBUG=0

# UI functions
# ------------------------------------------------------------------------------
error() {
  echo -e "${C_RED}[ERROR]${C_STD}  $1"
  [[ $2 == '-ec' ]] && exit $3
}

ok() {
  echo -e "${C_GREEN}[ OK ]${C_STD}  $1"
}

debug() {
  (( ${KAWS_DEBUG} )) && echo -e "${C_PURPLE}[DEBUG]${C_STD}  ${1}"
}

# Validation functions
# ------------------------------------------------------------------------------
save2conf() {
  key=$1
  value=$2
  line="${key}=${value}"

  if [[ ! -f ${CONFIG_FILE} ]]; then
    echo -en "\n$line\n" > ${CONFIG_FILE}
  elif grep -q -v "${key}=" ${CONFIG_FILE}; then
    echo -en "\n$line\n" >> ${CONFIG_FILE}
  else
    sed -i -e "s/${key}=.*/${line}/" ${CONFIG_FILE}
    rm -f ${CONFIG_FILE}-e
  fi
}

check_requirements() {
  debug "Checking requirements:"
  
  # Commands:
  err=
  for cmd in kube-aws kubectl jq aws; do
    if [[ -z $(command -v ${cmd} 2>/dev/null) ]]; then
      error "${C_YELLOW}${cmd}${C_STD} not found"
      err="${C_YELLOW}${cmd}${C_STD}, ${err}"
    else 
      debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}${cmd}${C_STD} installed"
    fi
  done
  [[ -n ${err} ]] && error "\nInstall the following commands: ${err%, }\n" -ec 1

  # AWS Configuration
  if [[ ! -f ~/.aws/config ]]; then
    error "AWS is not configured"
    echo -ne "\nConfigure AWS with ${C_YELLOW}aws configure${C_STD}\n"
    exit 1
  else
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}aws${C_STD} configured"
  fi

  # KAWS Configuration
  err=
  for param in KAWS_KEY_NAME KAWS_DOMAIN_NAME; do
    eval p=\$${param}
    if [[ -z ${p} ]]; then
      error "${C_YELLOW}${param}${C_STD} cannot be empty"
      err="${C_YELLOW}${param}${C_STD}, ${err}"
    else
      debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}${param}${C_STD} = ${p}"
    fi
  done
  [[ -n ${err} ]] && error "\nAssign a value to the following environment variables: ${err%, }\n" -ec 1
}

masters_count=
workers_count=
etcds_count=
check_cluster_size() {
  if [[ "${KAWS_CUSTER_SIZE:0:3}" == "N:1" ]]; then
    error "cluster size cannot be multiple masters and one worker"
    exit 1
  fi

  masters_count=${KAWS_CUSTER_SIZE:0:1}
  workers_count=${KAWS_CUSTER_SIZE:2:1}
  etcds_count=${KAWS_CUSTER_SIZE:4:1}

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_CUSTER_SIZE${C_STD} = ${KAWS_CUSTER_SIZE} (M=${masters_count}, W=${workers_count}, E=${etcds_count})"
}

list_profiles() {
  echo "Profiles:"
  cat ~/.aws/config | grep "\[" | tr -d '[]' | cut -d " " -f 2 | while read profile
  do 
    echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${profile}"
  done
}

check_profile() {
  if [[ -z ${AWS_PROFILE} ]]; then
    error "the AWS profile cannot be empty. assign a default value"
    echo
    list_profiles
    exit 1
  fi
  
  if ! grep -q "\[\(profile \)*${AWS_PROFILE}\]" ~/.aws/config; then
    error "AWS profile ${C_YELLOW}${AWS_PROFILE}${C_STD} not found"
    echo
    list_profiles
    exit 1
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}AWS_PROFILE${C_STD} = ${AWS_PROFILE}"
}

list_regions() {
  echo "Regions:"
  aws --profile ${aws_profile} ec2 describe-regions | jq -r '.Regions[] | .RegionName' | while read reg
  do
    if [[ "${DEFAULT_AWS_REGION}" == "${reg}" ]]; then
      echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${C_YELLOW}${reg}${C_STD} ${C_GREEN}${I_CHECK}${C_STD}"
    else
      echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${reg}"
    fi
  done
}

check_region() {
  DEFAULT_AWS_REGION=$(aws configure get region --profile ${aws_profile})
  
  if [[ -z ${AWS_REGION} ]]; then
    AWS_REGION=${DEFAULT_AWS_REGION}
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}AWS_REGION${C_STD} = ${AWS_REGION} (default one)"
    return
  fi

  reg=$(aws --profile ${aws_profile} ec2 describe-regions --region-names ${AWS_REGION} 2>/dev/null | jq -r '.Regions[] | .RegionName')
  if [[ -z $reg ]]; then
    error "${C_YELLOW}${AWS_REGION}${C_STD} is not a valid region"
    [[ -n ${DEFAULT_AWS_REGION} ]] && echo -e "Try with ${C_WHITEBOLD}AWS_REGION=${C_YELLOW}${DEFAULT_AWS_REGION}${C_STD} or one of the following"
    echo 
    list_regions
    exit 1
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}AWS_REGION${C_STD} = ${AWS_REGION}"
}

list_az() {
  echo -e "Availability Zones for ${C_YELLOW}${aws_region}${C_STD}:"
  aws ec2 --profile ${aws_profile} --region ${aws_region} describe-availability-zones | jq -r '.AvailabilityZones[] | .ZoneName' | while read az
  do
    if [[ "${DEFAULT_AZ}" == "${az}" ]]; then
      echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${C_YELLOW}${az}${C_STD} ${C_GREEN}${I_CHECK}${C_STD}"
    else
      echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${az}"
    fi
  done
}

check_az() {
  DEFAULT_AZ=${aws_region}a
  [[ -z ${KAWS_AZ} ]] && KAWS_AZ=${DEFAULT_AZ}

  aws ec2 --profile ${aws_profile} --region ${aws_region} describe-availability-zones --zone-names ${KAWS_AZ} 2>&1 >/dev/null
  if [[ $? -ne 0 ]]; then
    error "invalid availability zone ${KAWS_AZ} in region ${aws_region}"
    echo -e "Assign to ${C_WHITEBOLD}KAWS_AZ${C_STD} a valid availability zone for ${C_YELLOW}${aws_region}${C_STD} from the following list"
    echo
    list_az
    exit 1
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_AZ${C_STD} = ${KAWS_AZ}"
}

list_keypairs() {
  echo "Key Pairs:"
  aws --profile ${aws_profile} ec2 describe-key-pairs | jq -r '.KeyPairs[] | .KeyName' | while read kp
  do
    echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${kp}"
  done
}

check_keypair() {
  if [[ -z ${KAWS_KEY_NAME} ]]; then
    error "key name cannot be empty"
    echo -e "Assign to ${C_WHITEBOLD}KAWS_KEY_NAME${C_STD} one of the following keys name"
    echo
    list_keypairs
    exit 1
  fi

  keynames=$(aws --profile ${aws_profile} ec2 describe-key-pairs 2>/dev/null | jq -r '.KeyPairs[] | .KeyName')
  if [[ -z $keynames ]]; then 
    error "not found any key pair"
    echo -e "Create a key pair and assign it to ${C_WHITEBOLD}KAWS_KEY_NAME${C_STD}"
    exit 1
  fi

  kp=$(aws --profile ${aws_profile} ec2 describe-key-pairs --key-names ${KAWS_KEY_NAME} 2>/dev/null | jq -r '.KeyPairs[] | .KeyName')
  if [[ -z $kp ]]; then
    error "key name ${C_YELLOW}${KAWS_KEY_NAME}${C_STD} not found"
    echo -e "Assign to ${C_WHITEBOLD}KAWS_KEY_NAME${C_STD} one of the following keys name"
    echo
    list_keypairs
    exit 1
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_KEY_NAME${C_STD} is a valid key name (${KAWS_KEY_NAME})"
}

check_cluster_name() {
  if [[ -z ${KAWS_CLUSTER_NAME} ]]; then
    error "kubernetes cluster name cannot be empty"
    echo -e "Use flag ${C_YELLOW}--cluster${C_STD} to set the kubernetes cluster name"
    usage 
    exit 1
  fi
  
  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_CLUSTER_NAME${C_STD} = ${KAWS_CLUSTER_NAME}" 
}

list_domains() {
  echo "Domains:"
  aws --profile ${aws_profile} route53 list-hosted-zones | jq -r '.HostedZones[].Name' | while read dn
  do
    echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${dn%.}"
  done
}

check_domain() {
  if [[ -z ${KAWS_DOMAIN_NAME} ]]; then
    error "domain name cannot be empty"
    echo -e "Assign to ${C_WHITEBOLD}KAWS_DOMAIN_NAME${C_STD} one of the following keys name"
    echo
    list_domains
    exit 1
  fi

  domains=$(aws --profile ${aws_profile} route53 list-hosted-zones 2>/dev/null | jq -r '.HostedZones[].Name')
  if [[ -z $domains ]]; then 
    error "not found any domain"
    echo -e "Create a Route 53 domain and assign it to ${C_WHITEBOLD}KAWS_DOMAIN_NAME${C_STD}"
    exit 1
  fi

  dn=$(aws --profile ${aws_profile} route53 list-hosted-zones-by-name --dns-name ${KAWS_DOMAIN_NAME} 2>/dev/null | jq -r '.HostedZones[].Name')
  if [[ -z $dn ]]; then
    error "domain name ${C_YELLOW}${KAWS_DOMAIN_NAME}${C_STD} not found"
    echo -e "Assign to ${C_WHITEBOLD}KAWS_DOMAIN_NAME${C_STD} one of the following domain names"
    echo
    list_domains
    exit 1
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_DOMAIN_NAME${C_STD} is a valid domain name in Route 53 (${KAWS_DOMAIN_NAME})"
}

list_buckets() {
  echo "S3 Buckets:"
  aws --profile $aws_profile s3 ls | cut -d " " -f3 | while read s3b
  do
    echo -e "${C_GREEN}${I_BULLET}${C_STD}  ${s3b}"
  done
}

check_bucket() {
  DEFAULT_BUCKET=${cluster_name}
  [[ -z ${KAWS_BUCKET} ]] && KAWS_BUCKET=${DEFAULT_BUCKET}

  aws --profile ${aws_profile} s3 ls ${KAWS_BUCKET} 2>&1 >/dev/null
  if [[ $? -ne 0 ]]; then
    [[ "${aws_region}" != "us-east-1" ]] && bucket_config="--create-bucket-configuration LocationConstraint=${aws_region}"
    aws s3api --profile ${aws_profile} --region ${aws_region} create-bucket --bucket ${KAWS_BUCKET} ${bucket_config} 2>&1 >/dev/null
    if [[ $? -ne 0 ]]; then
      error "failed to create s3 bucket with name ${C_YELLOW}${KAWS_BUCKET}${C_STD}"
      echo -e "Assign to ${C_WHITEBOLD}KAWS_BUCKET${C_STD} a valid name or one of the following s3 buckets"
      echo
      list_buckets
      exit 1
    fi

    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_BUCKET${C_STD} = ${KAWS_BUCKET} ${C_YELLOW}(created)${C_STD}"
    save2conf 'KAWS_BUCKET' ${KAWS_BUCKET}
    return
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_BUCKET${C_STD} is a valid S3 bucket (${KAWS_BUCKET})"
}

check_kms() {
  if [[ -z $KAWS_KMS ]]; then
    KAWS_KMS=$(aws --profile ${aws_profile} kms --region=${aws_region} create-key --description="Kubernetes cluster ${cluster_name} KMS key" | jq -r '.KeyMetadata | .Arn')
    [[ -z $KAWS_KMS ]] && error "failed to create the KMS" -ec 1
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_KMS${C_STD} = ${KAWS_KMS} ${C_YELLOW}(created)${C_STD}"
    save2conf 'KAWS_KMS' ${KAWS_KMS}
    return
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}KAWS_KMS${C_STD} = ${KAWS_KMS}"
}

aws_profile=
key_name=
domain_name=
cluster_name=
dns_name=
hosted_zone_id=
bucket_name=
aws_region=
availability_zone=
kms_key_arn=
setup() {
  debug "Input validations:"

  check_cluster_size

  check_profile
  aws_profile=${AWS_PROFILE}

  check_region
  aws_region=${AWS_REGION}

  check_az
  availability_zone=${KAWS_AZ}

  check_keypair
  key_name=${KAWS_KEY_NAME}

  check_cluster_name
  cluster_name=${KAWS_CLUSTER_NAME}

  environment=${KAWS_ENVIRONMENT}

  check_domain
  domain_name=${KAWS_DOMAIN_NAME}
  dns_name="${cluster_name}.${domain_name}"

  hosted_zone_id=$(aws --profile ${aws_profile} route53 list-hosted-zones | jq -r '.HostedZones[] | select(.Name=="'${domain_name}'.") | .Id' | cut -d "/" -f3)
  [[ -z $hosted_zone_id ]] && error "failed to identify the hosted zone id for ${C_YELLOW}${domain_name}${C_STD}" -ec 1
  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}hosted zone id${C_STD} = ${hosted_zone_id}"

  check_bucket
  bucket_name=${KAWS_BUCKET}

  check_kms
  kms_key_arn=${KAWS_KMS}

  mkdir -p ${CONFIG_DIR}
  echo "credentials" > ${CONFIG_DIR}/.gitignore
  cp ${CONFIG_FILE} ${CONFIG_DIR}
}

clean() {
  rm -rf ${CONFIG_DIR}
}

clean_kms() {
  if [[ -z $KAWS_KMS ]]; then
    error "unknown KMS Key or not defined. Use the ${C_YELLOW}KAWS_KMS${C_STD} environment variable or config setting"
    exit 1
  else
    echo -e "${C_YELLOW}Destroying the KMS key ${C_RED}${KAWS_KMS}${C_STD}"
    aws --profile ${AWS_PROFILE} kms schedule-key-deletion --key-id ${KAWS_KMS}
    sed -i -e '/^KAWS_KMS=.*/d' ${CONFIG_FILE}
    rm -f ${CONFIG_FILE}-e
    echo
  fi
}

clean_s3() {
  if [[ -z $KAWS_BUCKET ]]; then
    error "unknown S3 Bucket name or not defined. Use the ${C_YELLOW}KAWS_BUCKET${C_STD} environment variable or config setting"
    exit 1
  else
    echo -e "${C_YELLOW}Destroying the S3 Bucket ${C_RED}${KAWS_BUCKET}${C_STD}"
    aws --profile ${AWS_PROFILE} s3 rb s3://${KAWS_BUCKET} --force 
    sed -i -e '/^KAWS_BUCKET=.*/d' ${CONFIG_FILE}
    rm -f ${CONFIG_FILE}-e
    echo
  fi
}

init() {
  cd ${CONFIG_DIR}

  echo -e "${C_BLUE}Create the configuration file 'cluster.yaml'${C_STD}"
  AWS_PROFILE=${aws_profile} kube-aws init \
    --cluster-name=${cluster_name} \
    --region=${aws_region} \
    --availability-zone=${availability_zone} \
    --hosted-zone-id=${hosted_zone_id} \
    --external-dns-name=${dns_name} \
    --key-name=${key_name} \
    --kms-key-arn=${kms_key_arn}
  echo

  cd ..
}

render() {
  cd ${CONFIG_DIR}
  
  echo -e "${C_BLUE}Create new credentials for the cluster${C_STD}"
  AWS_PROFILE=${aws_profile}  kube-aws render credentials --generate-ca
  echo
  
  echo -e "${C_BLUE}Create CloudFormation templates and UserData${C_STD}"
  AWS_PROFILE=${aws_profile}  kube-aws render stack
  echo

  cd ..
}

customize() {
  cd ${CONFIG_DIR}

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Calico:${C_STD} enabled"
  sed -i -e 's/# useCalico: false/useCalico: true/' cluster.yaml

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}CoreOS release channel:${C_STD} stable"
  sed -i -e 's/#releaseChannel: stable/releaseChannel: stable/' cluster.yaml
  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Container runtime:${C_STD} docker"
  sed -i -e 's/# containerRuntime: docker/containerRuntime: docker/' cluster.yaml
  

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Subnets:${C_STD} 3"
  sed -i -e "/^availabilityZone: ${availability_zone}$/s/.*/# &/" cluster.yaml
  if ! grep -q '^# KAWS: Subnets for the Kubernetes cluster$' cluster.yaml; then
    cat <<EOSNET >> cluster.yaml
# KAWS: Subnets for the Kubernetes cluster
subnets:
- name: PublicSubnetA
  # private: true
  availabilityZone: ${aws_region}a
  instanceCIDR: "${KAWS_PUBLIC_SUBNET_A_CIDR}"
- name: PublicSubnetB
  # private: true
  availabilityZone: ${aws_region}b
  instanceCIDR: "${KAWS_PUBLIC_SUBNET_B_CIDR}"
- name: PublicSubnetC
  # private: true
  availabilityZone: ${aws_region}c
  instanceCIDR: "${KAWS_PUBLIC_SUBNET_C_CIDR}"
EOSNET
  fi


  if [[ "${masters_count}" == "1" ]]; then
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Controllers:${C_STD} 1 (default: one at AZ '${availability_zone}')"
  elif [[ "${masters_count}" == "N" ]]; then
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Controllers:${C_STD} 2 (1 per AZ)"
    if ! grep -q '^# KAWS: Controller config with subnets for the Kubernetes cluster$' cluster.yaml; then
      cat <<EOCTRLR >> cluster.yaml
# KAWS: Controller config with subnets for the Kubernetes cluster
controller:
  createTimeout: PT60M
  instanceType: t2.medium
  instanceTags:
    Role: controller
    SubRole: Development
    Application: Kubernetes
  rootVolume:
    size: 30
    type: gp2
  autoScalingGroup:
    minSize: 2
    maxSize: 3
    rollingUpdateMinInstancesInService: 2
  subnets:
  - name: PublicSubnetA
  - name: PublicSubnetB
  - name: PublicSubnetC
  nodeLabels:
    kube-aws.coreos.com/role: controller
EOCTRLR

    fi
  fi

  if [[ "${workers_count}" == "1" ]]; then
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Workers:${C_STD} 1 (default: one per AZ)"
  elif [[ "${workers_count}" == "N" ]]; then
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Workers:${C_STD} 3 (1-3 per AZ)"
    if ! grep -q '^# KAWS: Workers config with subnets for the Kubernetes cluster$' cluster.yaml; then
      sed -i -e '/^worker:$/s/.*/# &/' cluster.yaml
      sed -i -e '/  nodePools:/s/.*/# &/' cluster.yaml
      sed -i -e '/.*# Name of this node pool. Must be unique among all the node pools in this cluster.*/s/.*/# &/' cluster.yaml
      sed -i -e '/.*name: nodepool1.*/s/.*/# &/' cluster.yaml
      cat <<EOWRKR >> cluster.yaml
# KAWS: Workers config with subnets for the Kubernetes cluster
worker:
  nodePools:
    - name: nodepool1
      subnets:
      - name: PublicSubnetA
      instanceType: t2.medium
      instanceTags:
        Role: worker
        Environment: Development
        Application: Kubernetes
      rootVolume:
        size: 30
        type: gp2
      createTimeout: PT60M
      autoScalingGroup:
        minSize: 1
        maxSize: 3
        rollingUpdateMinInstancesInService: 2
      autoscaling:
        clusterAutoscaler:
          enabled: true
      nodeLabels:
        kube-aws.coreos.com/role: worker

    - name: nodepool2
      subnets:
      - name: PublicSubnetB
      instanceType: t2.medium
      instanceTags:
        Role: worker
        Environment: Development
        Application: Kubernetes
      rootVolume:
        size: 30
        type: gp2
      createTimeout: PT60M
      autoScalingGroup:
        minSize: 1
        maxSize: 3
        rollingUpdateMinInstancesInService: 2
      autoscaling:
        clusterAutoscaler:
          enabled: true
      nodeLabels:
        kube-aws.coreos.com/role: worker

    - name: nodepool3
      subnets:
      - name: PublicSubnetC
      instanceType: t2.medium
      instanceTags:
        Role: worker
        Environment: Development
        Application: Kubernetes
      rootVolume:
        size: 30
        type: gp2
      createTimeout: PT60M
      autoScalingGroup:
        minSize: 1
        maxSize: 3
        rollingUpdateMinInstancesInService: 2
      autoscaling:
        clusterAutoscaler:
          enabled: true
      nodeLabels:
        kube-aws.coreos.com/role: worker
EOWRKR

    fi
  fi

  if [[ "${etcds_count}" == "1" ]]; then
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Etcd:${C_STD} 1 (default: one at AZ '${availability_zone}')"
  elif [[ "${etcds_count}" == "N" ]]; then
    debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Etcd:${C_STD} 3 (one per AZ)"
    if ! grep -q '^# KAWS: Etcd config with subnets for the Kubernetes cluster$' cluster.yaml; then
      cat <<EOETCD >> cluster.yaml
# KAWS: Etcd config with subnets for the Kubernetes cluster
etcd:
  count: 3
  instanceType: t2.medium
  instanceTags:
    Role: etcd
    SubRole: Development
    Application: Kubernetes
  rootVolume:
    size: 30
    type: gp2
  dataVolume:
    size: 30
    type: gp2
    encrypted: false
  subnets:
  - name: PublicSubnetA
  - name: PublicSubnetB
  - name: PublicSubnetC
  snapshot:
    automated: true
  disasterRecovery:
    automated: true
EOETCD

    fi
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Forward logs to CloudWatch:${C_STD} disabled"
#   debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Forward logs to CloudWatch:${C_STD} enabled"
#   if ! grep -q '^# KAWS: Forward logs to CloudWatch$' cluster.yaml; then
#     cat <<EOCW >> cluster.yaml
# # KAWS: Forward logs to CloudWatch
# cloudWatchLogging:
#   enabled: true
#   retentionInDays: 7
#   localStreaming:
#     enabled: true
#     filter:  `{ $.priority = "CRIT" || $.priority = "WARNING" && $.transport = "journal" && $.systemdUnit = "init.scope" }`
#     interval: 60
# EOCW
#   fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Stack tags:${C_STD} Name:Kubernetes; Environment:${environment}"
  if ! grep -q '^# KAWS: Stack tags$' cluster.yaml; then
    cat <<EOST >> cluster.yaml
# KAWS: Stack tags
stackTags:
  Name: "Kubernetes"
  Environment: "${environment}"
EOST
  fi

  debug "${C_GREEN}${I_CHECK}${C_STD}  ${C_YELLOW}Add-ons:${C_STD} clusterAutoscaler"
  perl -i-e -p0e 's/  clusterAutoscaler:\n    enabled: false/  clusterAutoscaler:\n    enabled: true/igs' cluster.yaml
  # perl -i-e -p0e 's/  rescheduler:\n    enabled: false/  rescheduler:\n    enabled: true/igs' cluster.yaml
  # perl -i-e -p0e 's/  metricsServer:\n    enabled: false/  metricsServer:\n    enabled: true/igs' cluster.yaml


  rm -f ./cluster.yaml-e
  cd ..
}

validate_render() {
  cd ${CONFIG_DIR}

  echo -e "${C_BLUE}Validating all rendered files${C_STD}"
  AWS_PROFILE=${aws_profile} kube-aws validate --s3-uri=s3://${bucket_name}
  echo

  echo -e "${C_BLUE}Exporting the new cluster CloudFormation templates${C_STD}"
  AWS_PROFILE=${aws_profile} kube-aws up --s3-uri=s3://${bucket_name} --export --pretty-print
  echo 

  cd ..
}

initialize() {
  init
  render
  customize
  validate_render
  minimize
  makefile
}

launch() {
  cd ${CONFIG_DIR}

  echo -e "${C_BLUE}Launching the new cluster${C_STD}"
  AWS_PROFILE=${aws_profile}  kube-aws up --s3-uri=s3://${bucket_name}
  echo 

  cd ..
}

update() {
  cd ${CONFIG_DIR}

  echo -e "${C_BLUE}Destroying the cluster${C_STD}"
  AWS_PROFILE=${aws_profile} kube-aws update --s3-uri=s3://${bucket_name}
  echo

  cd ..
}

destroy() {
  cd ${CONFIG_DIR}

  name=$(grep 'clusterName:' cluster.yaml)
  region=$(grep 'region:' cluster.yaml)
  echo -e "${C_GREEN}Destroying the cluster ${C_YELLOW}${name}${C_STD} on the region ${C_YELLOW}${region}${C_STD}"
  AWS_PROFILE=$aws_profile kube-aws destroy
  echo

  cd ..
}

tests() {
  export KUBECONFIG=${CONFIG_DIR}/kubeconfig

  echo -e "${C_BLUE}Cluster info:${C_STD}"
  echo kubectl cluster-info
  kubectl cluster-info
  echo

  echo -e "${C_BLUE}Cluster status:${C_STD}"
  echo kubectl get componentstatuses
  kubectl get componentstatuses
  echo

  echo -e "${C_BLUE}Nodes:${C_STD}"
  echo kubectl get nodes
  kubectl get nodes
  echo

  echo -e "${C_BLUE}Pods:${C_STD}"
  echo kubectl get pods
  kubectl get pods
  echo

  echo -e "${C_BLUE}Services:${C_STD}"
  echo kubectl get services
  kubectl get services
  echo

  echo -e "${C_BLUE}Deployments on system namespace:${C_STD}"
  echo kubectl get deployments --namespace=kube-system
  kubectl get deployments --namespace=kube-system
  echo

  # echo "Run a pod:"
  # kubectl run quick-start-nginx --image=nginx --port=80
  # kubectl port-forward $(kubectl get pods -l "run=quick-start-nginx" -o jsonpath="{.items[0].metadata.name}") 8080:80
  # echo "open http://localhost:8080/"
  # [[ -d "/Applications/Google Chrome.app" ]] && /usr/bin/open -a "/Applications/Google Chrome.app" 'http://localhost:8080/'
  # kubectl expose deployment quick-start-nginx --port=80 --type=LoadBalancer

  # sleep 30s

  # [[ -d "/Applications/Google Chrome.app" ]] && /usr/bin/open -a "/Applications/Google Chrome.app"  http://$(kubectl get svc quick-start-nginx -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
  
  echo -e "${C_BLUE}Run a Pod:${C_STD}"
  echo kubectl apply -f example/kuard-pod.yaml
  kubectl apply -f example/kuard-pod.yaml
  echo 

  sleep 30s

  echo -e "${C_BLUE}Deployed Pod details:${C_STD}"
  echo kubectl describe pods kuard
  kubectl describe pods kuard
  echo

  echo -e "${C_BLUE}Access Kuard app:${C_STD}"
  echo kubectl port-forward kuard 8080:8080 &
  kubectl port-forward kuard 8080:8080 &
  echo "Open http://localhost:8080"
  [[ -d "/Applications/Google Chrome.app" ]] && /usr/bin/open -a "/Applications/Google Chrome.app" 'http://localhost:8080'

  echo

  echo -e "${C_BLUE}View logs:${C_STD}"
  echo kubectl logs -f kuard
  kubectl logs kuard
  echo

  read -p "Press enter to continue"

  echo -e "${C_RED}Delete the pod later with:${C_STD}"
  echo kubectl delete -f example/kuard-pod.yaml
  echo

  kill $(ps | grep '[k]ubectl port-forward kuard' | cut -f1 -d' ')
}

minimize() {
  if [[ ! -f ${CONFIG_DIR}/cluster.yaml ]]; then
    error "not found ${C_YELLOW}cluster.yaml${C_STD} file. The cluster config file need to exists."
    exit 1
  fi
  grep -v '^\s*#' ${CONFIG_DIR}/cluster.yaml | grep -v '^\s*$' > ${CONFIG_DIR}/cluster.min.yaml
}

makefile() {
  cp Makefile.tpl ${CONFIG_DIR}/Makefile
  kube_aws_version=$(kube-aws version)
  sed -i -e "s/^KUBE_AWS_VERSION 	=.*/KUBE_AWS_VERSION 	= ${kube_aws_version}/" ${CONFIG_DIR}/Makefile
  sed -i -e "s/^S3_BUCKET 	 =.*/S3_BUCKET 	 = ${bucket_name}/" ${CONFIG_DIR}/Makefile
  rm -f ${CONFIG_DIR}/Makefile-e
}

copy() {
  target=$1
  [[ ! -d $target ]] && error "not found target directory to copy the configuration (${target})" -ec 1
  [[ ! -d ${target}/.git ]] && error "not a git repository the target directory to copy the configuration (${target})" -ec 1

  minimize
  cp -R ${CONFIG_DIR}/* ${target}
}

ui() {
  export KUBECONFIG=${CONFIG_DIR}/kubeconfig

  echo "Open the dashboard at: http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/"
  echo "Select 'Skip' to login"
  echo "kubectl proxy"
  [[ -d "/Applications/Google Chrome.app" ]] && /usr/bin/open -a "/Applications/Google Chrome.app" 'http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/'
  kubectl proxy
}

# Usage function
# ------------------------------------------------------------------------------
usage() {
  echo -e "${C_GREEN}KAWS${C_STD} is a script for setting up a Kubernetes cluster on AWS"
  echo
  echo -e "${C_WHITEBOLD}Usage:${C_STD}"
  echo "  ${SCRIPT_NAME} [ command ] [ flags ]"
  echo
  echo -e "${C_WHITEBOLD}Commands:${C_STD}"
  echo "  help                      Print this help message"
  echo "  init                      Creates the configuration file for a Kubernetes cluster. Use 'init' to customize your cluster"
  echo "  up                        Launch the Kubernetes cluster. Creates the configuration files if it does not exists"
  echo "  update                    Update an existing Kubernetes cluster after modify the configuration file"
  echo "  down                      Destroy the Kubernetes cluster"
  echo "  test                      Execute some basic tests"
  echo "  ui                        Open the Kubernetes Dashboard"
  echo -e "  min                       Minify the configuration file to ${C_WHITEBOLD}./${DEFAULT_CONFIG_DIR_NAME}/cluster.min.yaml${C_STD}"
  echo "  clean                     Deletes all generated files"
  echo "  clean kms                 Deletes the KMS"
  echo "  clean s3                  Deletes S3 Bucket"
  echo
  echo -e "${C_WHITEBOLD}Flags:${C_STD}"
  echo "  -h | --help               Print this help message"
  echo "  --debug                   Enable debug mode. Or use KAWS_DEBUG. By default is disabled"
  echo -e "  --conf-dir <path>         Directory to store all the generated files. Default is ${C_WHITEBOLD}./${DEFAULT_CONFIG_DIR_NAME}${C_STD}"
  echo -e "  --conf <filename>         Load settings from this config file. Default is ${C_WHITEBOLD}${CONFIG_FILE}${C_STD}"
  echo -e "  --profile <aws profile>   AWS profile to use. Or use AWS_PROFILE. Default ${C_WHITEBOLD}${DEFAULT_AWS_PROFILE}${C_STD}"
  echo -e "  --cluster <cluster name>  Kubernetes cluster name. Or use KAWS_CLUSTER_NAME. Default ${C_WHITEBOLD}${DEFAULT_CLUSTER_NAME}${C_STD}"
  echo "  --s3 <s3 bucket name>     AWS S3 bucket name to store all the CloudFormation templates and User Data. Or use KAWS_BUCKET. Default is the cluster name."
  echo 
  echo -e "${C_YELLOW}Required Parameters as Flags${C_STD}"
  echo "  --key-pair <key pair>     AWS Key Pair"
  echo "  --domain <domain name>    Domain name in Route 53"
  echo 
  echo -e "${C_YELLOW}Required Parameters as Environment Variables${C_STD}"
  echo "  KAWS_KEY_NAME=<key pair>       AWS Key Pair"
  echo "  KAWS_DOMAIN_NAME=<domain name> Domain name in Route 53"
  echo 
  echo "Use the required flags or the required environment variables to enter"
  echo "the required parameters. If both are used, the flags have preference."
  echo -e "It's allowed to define the environment variables in the file ${C_WHITEBOLD}${CONFIG_FILE}${C_STD}"
  echo 
  echo -e "${C_WHITEBOLD}Example of ${CONFIG_FILE}${C_STD}"
  echo "  KAWS_KEY_NAME=demokeypair"
  echo "  KAWS_DOMAIN_NAME=demo.acme.com"
  echo "  # Optional:"
  echo "  KAWS_CLUSTER_NAME=demo"
  echo "  KAWS_BUCKET=acme-kube"
  echo "  AWS_PROFILE=acme"
  echo "  AWS_REGION=us-west-2"
  echo 
  echo -e "${C_WHITEBOLD}Quick Start${C_STD}"
  echo "  $0 up --key-pair demokeypair --domain demo.acme.com --cluster demo"
  echo "  $0 down"
  echo "  $0 clean"
}

# Main code
# ------------------------------------------------------------------------------
[[ $# -eq 0 ]] && usage && exit 0

action=
while (( "$#" )); do
  case $1 in
    -h | --help | help ) usage ; exit 0
    ;;
    --debug ) KAWS_DEBUG=1
    ;;
    --debug2 ) DEEP_DEBUG=1
    ;;
    --profile ) KAWS_AWS_PROFILE=$2 ; shift
    ;;
    --conf )
      if [[ ! -f $2 ]]; then
        error "config file ${C_YELLOW}$2${C_STD} not found"
        exit 1
      fi
      CONFIG_FILE=$2
      source ${CONFIG_FILE}
      shift
    ;;
    --conf-dir )
      CONFIG_DIR=$2
      shift
    ;;
    --cluster ) KAWS_CLUSTER_NAME=$2 ; shift
    ;;
    --key-pair ) KAWS_KEY_NAME=$2 ; shift
    ;;
    --domain ) KAWS_DOMAIN_NAME=$2 ; shift
    ;;
    --s3 ) KAWS_BUCKET=$2 ; shift
    ;;
    init ) action=init
    ;;
    min ) 
      minimize
      exit 0
    ;;
    up ) action=create
    ;;
    update ) action=update
    ;;
    test ) action=test
    ;;
    cp )
      [[ -z $2 ]] && error "missing directory to copy the cluster configuration" -ec 1
      copy "$2"
      exit 0
    ;;
    ui ) action=openui
    ;;
    down ) action=destroy
    ;;
    clean ) 
      case $2 in
        kms ) action=clean_kms
        ;;
        s3 ) action=clean_s3
        ;;
        '' ) 
          clean
          exit 0
        ;;
        * )
          error "unknown object to deleted ${C_YELLOW}$2${C_STD}"
          echo 
          usage
          exit 1
        ;;
      esac
      shift
    ;;
    * ) 
      error "unknown command or flag ${C_YELLOW}$1${C_STD}"
      echo
      usage
      exit 1
    ;;
  esac
  shift
done

if [[ -z ${action} ]]; then
  error "enter an action/command to execute"
  echo
  usage
  exit 0
fi

check_requirements

case ${action} in
  init ) 
    setup
    initialize
  ;;
  create )
    setup
    [[ ! -f ${CONFIG_DIR}/cluster.yaml ]] && initialize
    launch
  ;;
  update )
    setup
    update
  ;;
  test )
    [[ ! -f ${CONFIG_DIR}/kubeconfig ]] && error "not found ${C_YELLOW}kubeconfig${C_STD} file. The cluster need to exists." -ec 1
    tests
  ;;
  openui )
    [[ ! -f ${CONFIG_DIR}/kubeconfig ]] && error "not found ${C_YELLOW}kubeconfig${C_STD} file. The cluster need to exists." -ec 1
    ui
  ;;
  destroy )
    setup
    destroy
  ;;
  clean_kms )
    clean_kms
  ;;
  clean_s3 )
    clean_s3
  ;;
  * ) 
    error "unknown action ${C_YELLOW}${action}${C_STD}"
    usage
    exit 1
  ;;
esac

echo -e "${C_GREEN}${I_CHECK}  Done${C_STD}"